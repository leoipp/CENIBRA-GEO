{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoipp/CENIBRA-GEO/blob/main/Rotina_de_indica%C3%A7%C3%A3o_de_anomalia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6ED1YKmvcG-"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1gz4vgIvjL_lxInS--BPQ_w7hEDde2oRS\" width=130 height=130 align=\"left\">\n",
        "\n",
        "#‎‎‎ Rotina de Indicação de Anomalias | Áreas Fomento.\n",
        "#‎ Celulose Nipo-Brasileira S.A - CENIBRA.\n",
        "---\n",
        "---\n",
        "> ‎ Rotina de detecção de anomalias, áreas com potencial distúrbio florestal. O script é baseado fundamentalmente no índice de vegetação por diferença normalizada (*IVDN* ou *NDVI* em inglês). O NDVI é uma medida radiométrica adimensional criada para distinguir informações espectrais da vegetação em relação a demais superfícies.\n",
        "\n",
        "> Os valores do NDVI podem variar de *-1 a 1*, sendo *1* representado por maior densidade e vigor de cobertura vegetal da área amostrada. A maior amplitude do índice reflete um maior detalhamento das áreas vegetadas em contraste com o solo exposto e/ou impermeabilizados.\n",
        "\n",
        "> As imagens de satélite foram obtidas pelo programa espacial *Copernicus* com a missão *Sentinel 2*, que consiste em 2 satélites orbitando a terra. O objetivo é monitorar a variabilidade das condições da superficie terrestre, com imagens em latitude média em espaçamentos de 2-3 dias e resolução espacial para as bandas *B4, B3, B2 e B8(NIR)* de *10 metros*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Inicialização do ambiente\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jrR55iJ97bPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8fBD3pE3eMS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Instalação de pacotes não nativos do Colab.\n",
        "!pip install geemap geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lzGK2ltzk5cz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Importação de pacotes ao ambiente de execução.\n",
        "import ee\n",
        "import geemap\n",
        "import fiona\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import Point\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J-Jw2UR_mXsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7d9827-46ee-4425-e8cd-1bdd39c16131",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=-7nz9t_J8TOlI3mIhsRXeP1Ja8FpRwF7eM9gpdyRXD8&tc=J_6p2OBMI2c11CQTQWSQfYqpiGz4p-ybJ4AgdjoDu1Q&cc=R7TJwToBi-Nh3nUOd1gdrs8Z5CBmlB-uDvG71UYuF_c\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWivKVn3MwvZnOW3AfsBZ6MR2R9zv9qOYMDZxUnejA8zSy0A7wBP_-s\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "#@markdown Inicialização e autenticação para integração a plataforma Google Earth Engine.\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Seleção de parâmetros.\n",
        "---\n",
        "> Os `.shp` da base de dados de talhões foram previamente armazenados na núvem para aumento de velocidade de importação do usuário.\n",
        "\n",
        "O filtro criado s2cloudless para o dataset pode selecionar o limite de probabilidade de núvens, definindo uma máscara para núvens/não núvens.\n",
        "A identificação do limite para a probabilidade de cobertura de núvens pode ser feita pela interpretação do usuário do **Histograma de Probabilidade de Núvens**.\n",
        "Apenas máscaras agressivas irão permitir a remoção total de núvens da imagem, porém, podem eventualmente, remover pixels limpos.\n",
        "\n",
        "Definição de parâmetros utilizados para filtrar a colgeção de imagens Sentinel 2 e determinar a identificação de núvens e projeção de sombra de núvens.\n",
        "\n",
        "|Parâmetro | Tipo | Descrição |\n",
        "| :-- | :-- | :-- |\n",
        "| `AOI` | `ee.Geometry` | Área de interesse |\n",
        "| `Data_inicio` | string | Início da coleção de imagens (inclusivo) |\n",
        "| `data_final` | string | Fim da coleção de imagens (exclusivo) |\n",
        "| `Filtro_nuvens` | integer | Percentual de cobertura máximo permitido na coleção de imagens |\n",
        "| `Prob_limite_nuvens` | integer | Probabilidade de núvens (%); valores maiores que, sao considerados núvens |\n",
        "| `Px_nao_agua` | float | Reflectância do vermelho proximo (NIR); valores menores que sao considerados pontos potenciais de sombras de núvens |\n",
        "| `Projecao_nuvens` | float | Distância máxima (km) para procurar por sombras e bordas das núvens |\n",
        "| `BUFFER` | integer | Distância (m) para dilatação das bordas de objetos identificados como núvens |\n",
        "\n",
        "Quando parametrizando e avaliando máscaras de núvens para uma nova área, é uma boa prática identificar uma única data e limitar a extensão da regonal para minimizar requerimentos de processamento. \n",
        "\n",
        "**OBS:** Os dados de [Refecltância da superfície Sentinel-2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR) e [Probabilidade de núvens Sentinel-2](https://developers.google.com/earth-engine/datasets/catalogCOPERNICUS_S2_CLOUD_PROBABILITY) são diferentes coleções de imagens. Cada coleção deve ser filtrada similarmente (ex. por data e extensão) e entao estas duas coleções filtradas devem ser sofrer junção.\n",
        "\n",
        "Definir uma função para filtrar o SR e a coleção do S2 sem núves de acordo com a área de interesse e parâmetros de data, a junção ocorrerá pela propriedade de `system:index`. O resultando é uma cópia da coleção SR onde cada imagem tem uma nova propriedade `\"s2cloudless\"` no qual o valor é correspondente a imagem S2 sem núvens.\n",
        "\n",
        "Definir uma função para adicionar pixels escuros, projeção de núvens e identificar sombras como bandas para o input de imagem S2 SR. **OBS:** O input da imagem necessita ser o resultado da função `ADD_BNuvem`, porque esta depende do conhecimento em consideração de cada pixel ser núvem ou não (Banda `clouds`)"
      ],
      "metadata": {
        "id": "njRTMpVz7jH-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ONaVdR4Ymg1p",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Camada de área de interesse\n",
        "AOI_GN = ee.Geometry.Polygon(\n",
        "        [[[-43.45230715090038,-19.123106898376598],\n",
        "          [-41.99936525636913,-19.123106898376598],\n",
        "          [-41.99936525636913,-18.016604678857952],\n",
        "          [-43.45230715090038,-18.016604678857952]]], None)\n",
        "\n",
        "# Camada de área de interesse\n",
        "AOI_NE = ee.Geometry.Polygon(\n",
        "        [[[-43.56741785025536,-20.25056297245866],\n",
        "          [-42.54843591666161,-20.25056297245866],\n",
        "          [-42.54843591666161,-18.98807690624204],\n",
        "          [-43.56741785025536,-18.98807690624204]]], None)\n",
        "\n",
        "# Camada de área de interesse\n",
        "AOI_RD = ee.Geometry.Polygon(\n",
        "        [[[-42.69306006150326,-20.421412226789364],\n",
        "          [-41.68231787400326,-20.421412226789364],\n",
        "          [-41.68231787400326,-18.3332108430093],\n",
        "          [-42.69306006150326,-18.3332108430093]]], None)\n",
        "\n",
        "# Acesso de dados no GEE\n",
        "feature = \"users/leoippef/BASE_FOMENTO\"#@param {type:\"string\"}\n",
        "regiao = \"RD\"#@param {type:\"string\"}\n",
        "Areas_fomento = ee.FeatureCollection(feature).filter(ee.Filter.eq('REGIAO_ID', regiao))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "0OZKhQOKDPEN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "Data_Inicial = '2022-04-01'#@param {type:\"date\"}\n",
        "Data_Final = '2022-05-01'#@param {type:\"date\"}\n",
        "Data_inicio = ee.Date.fromYMD(int(Data_Inicial.split('-')[0]),int(Data_Inicial.split('-')[1]),int(Data_Inicial.split('-')[2]))\n",
        "Data_final = ee.Date.fromYMD(int(Data_Final.split('-')[0]),int(Data_Final.split('-')[1]),int(Data_Final.split('-')[2]))\n",
        "Filtro_nuvens = 30 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "Prob_limite_nuvens = 15 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "Px_nao_agua = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "Projecao_nuvens = 1 #@param {type:\"number\"}\n",
        "BUFFER = 10 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Definição de funções e metadados das imagens selecionadas.\n",
        "---\n",
        "> **OBS:** O output da função `Sentinel2`, será uma ImageCollection sem a aplicação dos filtros de máscara de núvens e projeção de sombras. Enquanto o `.median()` do valor `s2_sr_median` irá agregar todas imagens coletadas e realizar a média dos valores das bandas para o período especificado.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t-AgAlEG7q8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "aCihFPm-C6UU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Funções\n",
        "def Sentinel2(aoi, Data_inicio, Data_final, Filtro_nuvens):\n",
        "  \n",
        "  # Importar e filtrar Sentinel 2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(Data_inicio, Data_final)\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', Filtro_nuvens)))\n",
        "\n",
        "    # Importar e filtrar sentinel 2 sem nuvens.\n",
        "    s2_semnuvem_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(Data_inicio, Data_final))\n",
        "\n",
        "    # Junção da coleção s2 sem nuvens com a coleção SR pela propriedade \"system:index\".\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{'primary': s2_sr_col,'secondary': s2_semnuvem_col, 'condition': ee.Filter.equals(**{'leftField': 'system:index','rightField': 'system:index'})}))\n",
        "\n",
        "\n",
        "def Add_BNuvem(img):\n",
        "  # Pegar imagens s2 sem nuvens, criando um subset de bandas de probabilidade.\n",
        "  prob_nuvem = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "  # Condição de s2 sem nuvens pelo valor limite de probabilidade.\n",
        "  enuvem = prob_nuvem.gt(Prob_limite_nuvens).rename('clouds')\n",
        "\n",
        "  # Adicionar o layer de probabilidade e mascara de nuvens como bandas na imagem.\n",
        "  return img.addBands(ee.Image([prob_nuvem, enuvem]))\n",
        "\n",
        "\n",
        "def Add_BSombras(img):\n",
        "    # Identificação de pixels de agua da banda SCL.\n",
        "    naoagua = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identificação de pixels escuros NIR que nao sao agua (potencialmente pixels de sombra de nuvens).\n",
        "    SR_BESCALA = 1e4\n",
        "    pixels_escuros = img.select('B8').lt(Px_nao_agua*SR_BESCALA).multiply(naoagua).rename('pixels_escuros')\n",
        "\n",
        "    # Determinar a direção de projeção de sombras de nuvens (Assumindo projeção UTM).\n",
        "    Azimuth_sombreado = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Projetar sombras de nuvens para distancia especificada pelo input de Projecao_nuvens.\n",
        "    projecao_nuvem = (img.select('clouds').directionalDistanceTransform(Azimuth_sombreado, Projecao_nuvens*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identificar a interseção de pixels escuros com projeção de sombra de nuvens.\n",
        "    sombras = projecao_nuvem.multiply(pixels_escuros).rename('sombras')\n",
        "\n",
        "    # Adicionar pixels escuros, projeção de nuvens, e sombras identificadas como bandas na imagem.\n",
        "    return img.addBands(ee.Image([pixels_escuros, projecao_nuvem, sombras]))\n",
        "\n",
        "\n",
        "def Add_BNS(img):\n",
        "    # Adicionar componentes da banda de nuvens.\n",
        "    img_nuvem = Add_BNuvem(img)\n",
        "\n",
        "    # Adicionar componente de sombra de nuvens.\n",
        "    img_nuvem_shadow = Add_BSombras(img_nuvem)\n",
        "\n",
        "    # Combinar mascara de nuvens e sombra, selecionar nuvem e sombra como valores 1 e o resto como 0.\n",
        "    e_sombreamento = img_nuvem_shadow.select('clouds').add(img_nuvem_shadow.select('sombras')).gt(0)\n",
        "\n",
        "    # Remover pequenas areas de sombras de nuvens e dilatar os pixels remanescentes pelo input do Buffer.\n",
        "    # 20 metros de escala para maior velocidade, assumindo que a analise nao necessite de 10 m de precisão.\n",
        "    e_sombreamento = (e_sombreamento.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 10})\n",
        "        .rename('cloudmask'))\n",
        "\n",
        "    # Adicionar uma máscara final de sombreamento de nuvens na imagem.\n",
        "    return img_nuvem_shadow.addBands(e_sombreamento)\n",
        "\n",
        "\n",
        "def App_CSmask(img):\n",
        "    # Subset a banda da mascara de nuvens e inverter, assim nuvem/sombras são 0, e o restante 1.\n",
        "    nao_sombras = img.select('cloudmask').Not()\n",
        "\n",
        "    # Subset das bandas de reflectancia e atualização das mascaras, retornando o resultado.\n",
        "    return img.select('B.*').updateMask(nao_sombras)\n",
        "\n",
        "def addNDVI (image):\n",
        "  ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "  return image.addBands(ndvi)\n",
        "\n",
        "if regiao == \"NE\":\n",
        "  # Obter coleção de imagem crua do Sentinel 2.\n",
        "  s2 = Sentinel2(AOI_NE, Data_inicio, Data_final, Filtro_nuvens)\n",
        "  # s2 = s2.map(addNDVI)\n",
        "\n",
        "  # Aplicação de mascara de nuvens/sombras na Coleção de Imagens.\n",
        "  # Converter uma coleção de imagens em uma unica imagem atraves da funcao median().\n",
        "  s2_sr_cld_col_eval_disp = s2.map(Add_BNS)\n",
        "  s2_sr_median = (s2.map(Add_BNS).map(App_CSmask).map(addNDVI).median()) \n",
        "\n",
        "if regiao == \"GN\":\n",
        "  # Obter coleção de imagem crua do Sentinel 2.\n",
        "  s2 = Sentinel2(AOI_GN, Data_inicio, Data_final, Filtro_nuvens)\n",
        "  # s2 = s2.map(addNDVI)\n",
        "\n",
        "  # Aplicação de mascara de nuvens/sombras na Coleção de Imagens.\n",
        "  # Converter uma coleção de imagens em uma unica imagem atraves da funcao median().\n",
        "  s2_sr_cld_col_eval_disp = s2.map(Add_BNS)\n",
        "  s2_sr_median = (s2.map(Add_BNS).map(App_CSmask).map(addNDVI).median())\n",
        "if regiao == \"RD\":\n",
        "  # Obter coleção de imagem crua do Sentinel 2.\n",
        "  s2 = Sentinel2(AOI_RD, Data_inicio, Data_final, Filtro_nuvens)\n",
        "  # s2 = s2.map(addNDVI)\n",
        "\n",
        "  # Aplicação de mascara de nuvens/sombras na Coleção de Imagens.\n",
        "  # Converter uma coleção de imagens em uma unica imagem atraves da funcao median().\n",
        "  s2_sr_cld_col_eval_disp = s2.map(Add_BNS)\n",
        "  s2_sr_median = (s2.map(Add_BNS).map(App_CSmask).map(addNDVI).median())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ylkV19CVE-QE",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121db4f7-964f-4e26-8955-8d9fd6ced891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Período de obtenção: Início em 2022-04-18 / Fim em 2022-04-28\n",
            "Para os parametros selecionados, você obteve: 18 Imagens.\n"
          ]
        }
      ],
      "source": [
        "#@markdown Metadata da coleção de imagens adquirirdas no Google Earth Engine API\n",
        "# Metadata da coleção de imagens adquirirdas no Google Earth Engine API.\n",
        "# Obter o range de datas com formato já convertido.\n",
        "range = s2.reduceColumns(ee.Reducer.minMax(), [\"system:time_start\"])\n",
        "Data_inicio = ee.Date(range.get('min')).format(\"YYYY-MM-dd\")\n",
        "Data_final = ee.Date(range.get('max')).format(\"YYYY-MM-dd\")\n",
        "print(f'Período de obtenção: Início em {Data_inicio.getInfo()} / Fim em {Data_final.getInfo()}')\n",
        "# Obter o numero de imagens na coleção.\n",
        "print(f'Para os parametros selecionados, você obteve: {s2.size().getInfo()} Imagens.') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Amostragem de NDVI para talhões.\n",
        "---\n",
        "> Para extrair os valores `NDVI` o Google drive precisa estar adicionado a pasta do notebook. Para isto, disponibilize o token de acesso ao rodar `drive.mount()`.\n",
        "\n",
        "> **OBS:** A exportação dos shapefiles `NDVI` aconteceram em pasta previamente criada pelo usuário, esta deve ser o caminho `work_dir`. Caso nao tenha uma pasta identificada para exportação, a mesma não ocorrerá.\n",
        "\n",
        "\n",
        "\n",
        "> **OBS.2:**: Atualmente a função `zonal_statistics()` pode calcular um tipo por vez, sendo estes `MEAN, MAXIMUM, MINIMUM, MEDIAN, STD, MIN_MAX, VARIANCE, SUM`.\n",
        "\n",
        "> **A exportação dos `.shp` podem levar aproximadamente 15 min ou mais**\n",
        "\n",
        "> Certamente quando talhões apresentarem valores de `NaN` para o atributo de **NDVI** a área amostrada está **contaminada por densa cobertura de núvens**. A aplicação da máscara de núvens irá suprimir a área deixando um \"buraco\" na imagem, portanto, não obtendo valor.\n",
        "\n",
        "> Neste caso, recomenda-se a utilização de outra coleção de imagens de salite, como exemplo o **MODIS**, porém a resolução da banda será prejudicada, neste exemplo será de 250 metros de resolução espacial.\n",
        "\n",
        "> A princípio haverá somente análise em talhões maduros (maiores que dois anos desde o plantio).\n",
        "\n",
        "> Pode-se avaliar talhões jovens que já sofreram análise de sobrevivencia, caso haja necessidade.\n",
        "\n"
      ],
      "metadata": {
        "id": "LXgKUZD574En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NDVI = s2_sr_median.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "# Seleção de pasta destino (pré criada) para exportação dos .shp.\n",
        "work_dir = \"/content/drive/MyDrive/Fomento_CENIBRA\"#@param {type: 'string'}\n",
        "\n",
        "# input do nome do output da camada de valores extraidas a partir da imagem NDVI.\n",
        "# Este passo pode levar alguns minutos para completar.\n",
        "out_shp_mean = os.path.join(work_dir, 'ZONAL_MEAN.shp')\n",
        "geemap.zonal_statistics(NDVI, Areas_fomento, out_shp_mean, statistics_type='MEAN', scale=10)\n",
        "\n",
        "\n",
        "out_shp_min_max = os.path.join(work_dir, 'ZONAL_MIN_MAX.shp')\n",
        "geemap.zonal_statistics(NDVI, Areas_fomento, out_shp_min_max, statistics_type='MIN_MAX', scale=10)\n",
        "\n",
        "out_shp_variance = os.path.join(work_dir, 'ZONAL_VAR.shp')\n",
        "geemap.zonal_statistics(NDVI, Areas_fomento, out_shp_variance, statistics_type='VARIANCE', scale=10)"
      ],
      "metadata": {
        "id": "C56ZqGFFZkrX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur93qvBpbxqD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Talhoes\n",
        "# Abertura dos .shp anteriormente exportados para o drive.\n",
        "ndvi_mean = gpd.read_file('/content/drive/MyDrive/Fomento_CENIBRA/ZONAL_MEAN.shp')\n",
        "ndvi_min_max = gpd.read_file('/content/drive/MyDrive/Fomento_CENIBRA/ZONAL_MIN_MAX.shp')\n",
        "ndvi_variance = gpd.read_file('/content/drive/MyDrive/Fomento_CENIBRA/ZONAL_VAR.shp')\n",
        "\n",
        "ndvi_min_max['REF_ID'] = ndvi_min_max.REGIAO + ndvi_min_max.ID_PROJETO + ndvi_min_max.LOTE + '-' + ndvi_min_max.TALHAO\n",
        "# Criando uma copia para integração de colunas em um GeoDataFrame unico.\n",
        "NDVI = ndvi_min_max.copy()\n",
        "\n",
        "\n",
        "if 'mean' in ndvi_mean:\n",
        "  # Conversão de formato str para datetime.\n",
        "  NDVI['Date'] = pd.to_datetime(NDVI['DATA_DE_PL'])\n",
        "  NDVI = NDVI.drop(columns=['DATA_DE_PL'])\n",
        "  # Cria o campo idade em meses\n",
        "  NDVI[\"IDADE_MESES\"] = NDVI[\"Date\"].apply(lambda x : round((dt.datetime.now() - x)/np.timedelta64(1,'M')))\n",
        "\n",
        "  # Adição de colunas em diferetes .shp em uma unica.\n",
        "\n",
        "  NDVI['mean'] = ndvi_mean['mean']\n",
        "  NDVI['variance'] = ndvi_variance['variance']\n",
        "\n",
        "  # Análise descritiva dos dados (n. de linhas e colunas e quantidade de NaN valores).\n",
        "  print(f'O GeoDataFrame possui {(NDVI.shape)[0]} Linhas / {(NDVI.shape)[1]} Colunas')\n",
        "  # print(NDVI.isnull().sum())\n",
        "\n",
        "  # Checar o index de NDVI para NaN valores, caso exista.\n",
        "  x = NDVI.loc[pd.isnull(NDVI[\"mean\"]), :].index\n",
        "\n",
        "  # Remover NaN valores (interseção com núvens NDVI=0)\n",
        "  NDVI = NDVI[NDVI['mean'].notna()]\n",
        "  print(' ******************************************************')\n",
        "  print(' *************** REMOÇÃO DE NAN VALORES ***************')\n",
        "  print(' ******************************************************')\n",
        "  print(f'O GeoDataFrame possui {(NDVI.shape)[0]} Linhas / {(NDVI.shape)[1]} Colunas')\n",
        "\n",
        "  # Seleção de talhoes jovens e maduros.\n",
        "  Talhoes_maduros = NDVI[NDVI['IDADE_MESES'] > 24]\n",
        "  Talhoes_jovens = NDVI[NDVI['IDADE_MESES'] <= 24]\n",
        "\n",
        "  # Seleção de áreas saudáveis (NDVI MÉDIO >= .55).\n",
        "  Nao_anomalos = Talhoes_maduros[Talhoes_maduros['mean'] >= 0.55]\n",
        "  # Seleção de talhoes anomalos.\n",
        "  Anomalos= Talhoes_maduros[Talhoes_maduros['mean']< 0.55].reset_index(drop=True)\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "  # Descrição de valores encontrando em áreas com potencial distúrbio.\n",
        "  print(f'> Número de Talhões potencialmente com disturbio: {Anomalos[\"mean\"].describe()[0]} \\n> Valor de NDVI médio mais baixo entre Talhões: {Anomalos[\"mean\"].describe()[3]} \\n> Valor de NDVI médio mais alto entre Talhões: {Anomalos[\"mean\"].describe()[7]} \\n> Média de NDVI médio entre Talhões com potencial distúrbio: {Anomalos[\"mean\"].describe()[1]}')\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "  Anomalos_T = Anomalos.copy()\n",
        "  # REF ID de talhões com potencial distúrbio\n",
        "  a = 0\n",
        "  for i in Anomalos.REF_ID:\n",
        "    a = a + 1\n",
        "    print(f'ID de Referência do Talhão: {a}/{len(Anomalos)} - Com Potencial Distúrbio: {i}')\n",
        "\n",
        "\n",
        "\n",
        "  Anomalos = Anomalos.drop(columns=['Date', 'IDADE_MESES'])\n",
        "\n",
        "else:  \n",
        "  print(' *******************************************************************************')\n",
        "  print('ALTA DENSIDADE DE NÚVENS RECOBRINDO A AOI PARA O PERÍODO E FILTROS ESPECIFICADOS')\n",
        "  print(' *******************************************************************************')\n",
        "  print('************************ SEGUINDO PARA AMOSTRAGEM POR PONTOS *******************')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Amostragem de NDVI para pontos.\n",
        "---\n",
        "> As amostras de 50 x 50m foram criadas previamente no *software ArcGIS PRO*, pela ferramente `FishNet`. As amostras foram então `'clipadas'` pelo poligono dos talhões com buffer de -12 metros, para evitar amostragem de pontos em pixel de estrada.\n",
        "\n",
        "\n",
        "> As propriedades dos talhões e pontos sofreram `'junção espacial'` para então exportação para núvem, armazenada no Google Earth Engine para maior performance de captura dos dados.\n",
        "\n",
        "> Os passos seguem a extração de valores como no passo **4.** A FeatureCollection `Amostragem_px`, foi previamente armazenada em nuvem para aumento de performance do script na extração de valores de `NDVI`.\n",
        "\n",
        "> Haverá também a extração de valores de presença de núvens em cada pixel e a probabilidade do pixel conter a cobertura de núvem cirrus.\n",
        "\n",
        "> **A exportação dos `.shp` podem levar aproximadamente 5 min ou mais**\n",
        "\n",
        "> Para facilitar a identificação de áreas com potencial disturbio, iremos localizar cada talhão e seu respectivo poligono pelo `groupby(Anomalos.REF_ID)`, que irá reporesentar a média de valores de NDVI para os pontos daquele local.\n",
        "\n"
      ],
      "metadata": {
        "id": "6JAnwILl8ATA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculo de NDVI\n",
        "NDVI = s2_sr_median.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "# Importação dos pontos de amostragem e filtro de feições TA03 e regioes RDBOBA\n",
        "feature = \"users/leoippef/BASE_AMOSTRAS_FOMENTO\"#@param {type: \"string\"}\n",
        "Amostragem_px = ee.FeatureCollection(feature).filter(ee.Filter.eq('REGIAO_ID', regiao))\n",
        "# Selecao de valores e probabilidade de núvem para filtrar dados\n",
        "img = s2_sr_cld_col_eval_disp.mosaic()\n",
        "clouds = img.select(['clouds', 'probability'])\n",
        "out_shp = os.path.join(work_dir, 'Amostragem_NUVEM.shp')\n",
        "geemap.extract_values_to_points(Amostragem_px, clouds, out_shp, scale=10)\n",
        "\n",
        "out_shp = os.path.join(work_dir, 'Amostragem_NDVIBUFFER.shp')\n",
        "geemap.extract_values_to_points(Amostragem_px, NDVI, out_shp, scale=10)"
      ],
      "metadata": {
        "id": "qDmVsdzLhiTt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Amostras\n",
        "Amostras_NDVI = gpd.read_file('/content/drive/MyDrive/Fomento_CENIBRA/Amostragem_NDVIBUFFER.shp')\n",
        "Amostras_nuvem = gpd.read_file('/content/drive/MyDrive/Fomento_CENIBRA/Amostragem_NUVEM.shp')\n",
        "\n",
        "if \"first\" in Amostras_NDVI:\n",
        "\n",
        "  Amostras_NDVI = Amostras_NDVI.rename(columns={'first': 'NDVI'})\n",
        "  Amostras_NDVI['REF_ID'] = Amostras_NDVI.REGIAO + Amostras_NDVI.ID_PROJETO + Amostras_NDVI.LOTE + '-' + Amostras_NDVI.TALHAO\n",
        "\n",
        "\n",
        "  # Junção de dados Nuvem com GeoDataFrame do NDVI\n",
        "  Amostras_NDVI['nuvem'] = Amostras_nuvem['clouds']\n",
        "  Amostras_NDVI['Prob_nuvem'] = Amostras_nuvem['probabilit']\n",
        "\n",
        "  # Conversão de formato str para datetime.\n",
        "  Amostras_NDVI['Date'] = pd.to_datetime(Amostras_NDVI['DATA_DE_PL'])\n",
        "  # Amostras_NDVI = Amostras_NDVI.drop(columns=['DATA_DE_PL'])\n",
        "  # Cria o campo idade em meses\n",
        "  Amostras_NDVI[\"IDADE_MESES\"] = Amostras_NDVI[\"Date\"].apply(lambda x : round((dt.datetime.now() - x)/np.timedelta64(1,'M')))\n",
        "\n",
        "\n",
        "  # Análise descritiva dos dados (n. de linhas e colunas e quantidade de NaN valores).\n",
        "  print(f'O GeoDataFrame possui {(Amostras_NDVI.shape)[0]} Pontos de Amostra / {(Amostras_NDVI.shape)[1]} Atributos')\n",
        "  #print(Amostras_NDVI.isna().sum())\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "\n",
        "  # Remover NaN valores (interseção com núvens NDVI=0)\n",
        "  Amostras_NDVI = Amostras_NDVI[Amostras_NDVI['NDVI'].notna()]\n",
        "  print(' **************** REMOÇÃO DE NAN VALORES **************')\n",
        "  print(' ******************************************************')\n",
        "  print(f'O GeoDataFrame possui {(Amostras_NDVI.shape)[0]} Pontos de Amostra / {(Amostras_NDVI.shape)[1]} Atributos')\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "\n",
        "\n",
        "\n",
        "  # Separação de Talhoes maduros e Talhoes Jovens.\n",
        "\n",
        "  Talhoes_maduros = Amostras_NDVI[Amostras_NDVI['IDADE_MESES'] > 24]\n",
        "  Talhoes_jovens = Amostras_NDVI[Amostras_NDVI['IDADE_MESES'] <= 24]\n",
        "  # Seleção de áreas saudáveis (NDVI MÉDIO >= .55).\n",
        "  Nao_anomalos = Talhoes_maduros[Talhoes_maduros['NDVI'] >= 0.55]\n",
        "\n",
        "  # Seleção de talhoes anomalos.\n",
        "  Anomalos= Talhoes_maduros[(Talhoes_maduros['NDVI']< 0.55) & (Talhoes_maduros['nuvem'] == 0) & (Talhoes_maduros['Prob_nuvem'] < 35)].reset_index(drop=True)\n",
        "\n",
        "\n",
        "  # Descrição de valores encontrando em áreas com potencial distúrbio.\n",
        "  print(f'> Número de Pontos potencialmente com disturbio: {Anomalos[\"NDVI\"].describe()[0]} \\n> Valor de NDVI mais baixo entre Talhões: {Anomalos[\"NDVI\"].describe()[3]} \\n> Valor de NDVI mais alto entre Talhões: {Anomalos[\"NDVI\"].describe()[7]} \\n> Média de NDVI entre Talhões com potencial distúrbio: {Anomalos[\"NDVI\"].describe()[1]}')\n",
        "\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "\n",
        "  Anomalias_group = Anomalos.groupby(Anomalos.REF_ID).mean().reset_index()\n",
        "  print(' *********** AGRUPAMENTO DE AMOSTRAS POR REF_ID *******')\n",
        "  print(' ******************************************************')\n",
        "  print(f'O GeoDataFrame possui {(Anomalias_group.shape)[0]} Pontos de Amostra / {(Anomalias_group.shape)[1]} Atributos')\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "  print(' ')\n",
        "\n",
        "  # Lista de referencia para extrair poligonos por ID\n",
        "  REFID = list(Anomalias_group.REF_ID)\n",
        "  # Criando uma copia para integração de colunas em um GeoDataFrame unico.\n",
        "  NDVI = ndvi_min_max.copy()\n",
        "  Anomalos_talhoes = gpd.GeoDataFrame()\n",
        "  for i in REFID:\n",
        "    for ii, n in NDVI.iterrows():\n",
        "      if i == n.REF_ID:\n",
        "        Anomalos_talhoes = Anomalos_talhoes.append(NDVI.loc[ii])\n",
        "  # Input de CRS para GeoDataFrame (Caso queira representar em `geemap()`)\n",
        "  Anomalos_talhoes.crs = \"EPSG:4326\"\n",
        "\n",
        "\n",
        "  # Identificar talhoes com média de NDVI que foram computados, mas nao estao presentes nesta amostragem\n",
        "  for i in list(Anomalos_talhoes.REF_ID):\n",
        "    for ii, n in Anomalos_T.iterrows():\n",
        "      if i == n.REF_ID:\n",
        "        Anomalos_T = Anomalos_T.drop(ii)\n",
        "\n",
        "  Anomalos_T = Anomalos_T.drop(columns=['mean', 'variance', 'Date', 'IDADE_MESES'])\n",
        "  Anomalos = Anomalos.drop(columns=['Date', 'IDADE_MESES'])\n",
        "\n",
        "  # Concatenar areas de poligono \n",
        "  Areas_anomalia = pd.concat([Anomalos_talhoes, Anomalos_T])\n",
        "  print('Processando cálculo de área para anomalias.....')\n",
        "\n",
        "  # Calculo de área para as anomalias\n",
        "\n",
        "  for i, n in Areas_anomalia.iterrows():\n",
        "    df = gpd.GeoDataFrame()\n",
        "    df = df.append(Areas_anomalia.loc[i])\n",
        "    df.crs = \"EPSG: 4326\"\n",
        "    aor = geemap.geopandas_to_ee(df)\n",
        "    s2_ndvi = s2_sr_median.select('NDVI')\n",
        "    sample = s2_ndvi.sample(aor, 10)\n",
        "    low = sample.filter(ee.Filter.lt('NDVI', 0.55))\n",
        "    low = low.aggregate_stats('NDVI').getInfo()\n",
        "    area = low['total_count']*100\n",
        "    Areas_anomalia.loc[i, 'Area_anomalia'] = area\n",
        "\n",
        "\n",
        "  # Exportar pontos anomalos e poligonos para formato KML\n",
        "  fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
        "  Areas_anomalia.to_file(f'Anomalos_talhoes_{regiao}.shp', driver='ESRI Shapefile')\n",
        "  # Anomalos.to_file('Anomalos_pontos.shp', driver='ESRI Shapefile')\n",
        "\n",
        "  print(f'Quantidade final de talhões: {len(Areas_anomalia)}')\n",
        "  print(' ******************************************************')\n",
        "  print(' ******************************************************')\n",
        "\n",
        "  if regiao == \"NE\":\n",
        "    out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_NE), description=out_nir, folder='export', scale=10)\n",
        "    out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_NE), description=out_ndvi, folder='export', scale=10)\n",
        "    out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_NE), description=out_rgb, folder='export', scale=10)\n",
        "  if regiao == \"GN\":\n",
        "    out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_GN), description=out_nir, folder='export', scale=10)\n",
        "    out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_GN), description=out_ndvi, folder='export', scale=10)\n",
        "    out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_GN), description=out_rgb, folder='export', scale=10)\n",
        "  if regiao == \"RD\":\n",
        "    out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_RD), description=out_nir, folder='export', scale=10)\n",
        "    out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_RD), description=out_ndvi, folder='export', scale=10)\n",
        "    out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "    geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_RD), description=out_rgb, folder='export', scale=10)\n",
        "\n",
        "\n",
        "else:  \n",
        "  print(' *******************************************************************************')\n",
        "  print('ALTA DENSIDADE DE NÚVENS RECOBRINDO A AOI PARA O PERÍODO E FILTROS ESPECIFICADOS')\n",
        "  print(' *******************************************************************************')\n",
        "  print('************************ NENHUMA AMOSTRA SELECIONADA *******************')\n",
        "\n",
        "\n",
        "  if \"first\" not in Amostras_NDVI and 'mean' in ndvi_mean :\n",
        "    Anomalos.crs = \"EPSG:4326\"\n",
        "    fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
        "    Anomalos.to_file(f'Anomalos_talhoes_{regiao}.shp', driver='ESRI Shapefile')\n",
        "    # Anomalos.to_file('Anomalos_pontos.shp', driver='ESRI Shapefile')\n",
        "\n",
        "    # Calculo de área para as anomalias\n",
        "\n",
        "    for i, n in Anomalos.iterrows():\n",
        "      df = gpd.GeoDataFrame()\n",
        "      df = df.append(Anomalos.loc[i])\n",
        "      df.crs = \"EPSG: 4326\"\n",
        "      aor = geemap.geopandas_to_ee(df)\n",
        "      s2_ndvi = s2_sr_median.select('NDVI')\n",
        "      sample = s2_ndvi.sample(aor, 10)\n",
        "      low = sample.filter(ee.Filter.lt('NDVI', 0.55))\n",
        "      low = low.aggregate_stats('NDVI').getInfo()\n",
        "      area = low['total_count']*100\n",
        "      Anomalos.loc[i, 'Area_anomalia'] = area\n",
        "\n",
        "    print(f'Quantidade final de talhões: {len(Anomalos)}')\n",
        "    print(' ******************************************************')\n",
        "    print(' ******************************************************')\n",
        "\n",
        "    if regiao == \"NE\":\n",
        "      out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_NE), description=out_nir, folder='export', scale=10)\n",
        "      out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_NE), description=out_ndvi, folder='export', scale=10)\n",
        "      out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_NE), description=out_rgb, folder='export', scale=10)\n",
        "    if regiao == \"GN\":\n",
        "      out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_GN), description=out_nir, folder='export', scale=10)\n",
        "      out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_GN), description=out_ndvi, folder='export', scale=10)\n",
        "      out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_GN), description=out_rgb, folder='export', scale=10)\n",
        "    if regiao == \"RD\":\n",
        "      out_nir = (f'RGB_NIR_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B8','B4', 'B3', 'B2']).clip(AOI_RD), description=out_nir, folder='export', scale=10)\n",
        "      out_ndvi = (f'NDVI_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['NDVI']).clip(AOI_RD), description=out_ndvi, folder='export', scale=10)\n",
        "      out_rgb = (f'RGB_{s2.size().getInfo()}_{regiao}_{Data_Inicial}')\n",
        "      geemap.ee_export_image_to_drive(s2_sr_median.select(['B4', 'B3', 'B2']).clip(AOI_RD), description=out_rgb, folder='export', scale=10)"
      ],
      "metadata": {
        "id": "G4hfQ7SN6kBi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Rotina de indicação de anomalia.ipynb",
      "provenance": [],
      "mount_file_id": "1F8s8Y4A72Ya9sC6PYAT6mLFraZa6cLk_",
      "authorship_tag": "ABX9TyPIUUiuH22YoiOPOjzpl9QT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}